{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#necessary Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import pprint\n",
    "\n",
    "#Visualizations\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pandas.plotting import scatter_matrix\n",
    "# magic word for producing visualizations in notebook\n",
    "%matplotlib inline\n",
    "\n",
    "#Preprocessing\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.decomposition import PCA \n",
    "from scipy.sparse import lil_matrix\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "#Models\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "from skmultilearn.problem_transform import ClassifierChain\n",
    "from skmultilearn.problem_transform import LabelPowerset\n",
    "from skmultilearn.adapt import MLkNN\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#Scoring Metrics\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import f1_score, fbeta_score\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "file_path = r'C:\\Users\\Thesis2.0\\django_thesis\\KNN Algorithm\\ap_data_2.csv'\n",
    "ap_data = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns: 9\n",
      "Number of rows: 11816\n"
     ]
    }
   ],
   "source": [
    "# Check the structure of the data after it's loaded \n",
    "#(print the number of rows and columns).\n",
    "num_rows, num_cols  = ap_data.shape\n",
    "print('Number of columns: {}'.format(num_cols))\n",
    "print('Number of rows: {}'.format(num_rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channel</th>\n",
       "      <th>signal_strength</th>\n",
       "      <th>floorid</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>11816.000000</td>\n",
       "      <td>11816.000000</td>\n",
       "      <td>11816.000000</td>\n",
       "      <td>11816.000000</td>\n",
       "      <td>11816.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2433.421378</td>\n",
       "      <td>-70.242891</td>\n",
       "      <td>137.270650</td>\n",
       "      <td>7.065780</td>\n",
       "      <td>125.596436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>17.130114</td>\n",
       "      <td>11.857180</td>\n",
       "      <td>39.880917</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.000034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2412.000000</td>\n",
       "      <td>-104.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.065631</td>\n",
       "      <td>125.596350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2417.000000</td>\n",
       "      <td>-79.000000</td>\n",
       "      <td>119.000000</td>\n",
       "      <td>7.065763</td>\n",
       "      <td>125.596407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2437.000000</td>\n",
       "      <td>-70.000000</td>\n",
       "      <td>143.000000</td>\n",
       "      <td>7.065786</td>\n",
       "      <td>125.596433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2447.000000</td>\n",
       "      <td>-61.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>7.065806</td>\n",
       "      <td>125.596465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2462.000000</td>\n",
       "      <td>-8.000000</td>\n",
       "      <td>189.000000</td>\n",
       "      <td>7.065841</td>\n",
       "      <td>125.596502</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            channel  signal_strength       floorid      latitude     longitude\n",
       "count  11816.000000     11816.000000  11816.000000  11816.000000  11816.000000\n",
       "mean    2433.421378       -70.242891    137.270650      7.065780    125.596436\n",
       "std       17.130114        11.857180     39.880917      0.000040      0.000034\n",
       "min     2412.000000      -104.000000      1.000000      7.065631    125.596350\n",
       "25%     2417.000000       -79.000000    119.000000      7.065763    125.596407\n",
       "50%     2437.000000       -70.000000    143.000000      7.065786    125.596433\n",
       "75%     2447.000000       -61.000000    166.000000      7.065806    125.596465\n",
       "max     2462.000000        -8.000000    189.000000      7.065841    125.596502"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check the statistics of the data per columns\n",
    "ap_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['mac_address', 'ssid', 'channel', 'source', 'signal_strength',\n",
       "       'floorid', 'latitude', 'longitude', 'timestamp'], dtype=object)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check the columns names\n",
    "col_names = ap_data.columns.values\n",
    "col_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent of missing data = 0.0%\n"
     ]
    }
   ],
   "source": [
    "#check for missing values\n",
    "missing_values_count = ap_data.isnull().sum()\n",
    "#uncomment this if you want to see the count of missing data per column\n",
    "#missing_values_count\n",
    "\n",
    "# how many total missing values do we have?\n",
    "total_cells = np.product(ap_data.shape)\n",
    "total_missing = missing_values_count.sum()\n",
    "\n",
    "# percent of data that is missing\n",
    "missing_percent = (total_missing/total_cells) * 100\n",
    "\n",
    "print('Percent of missing data = {}%'.format(missing_percent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a new column 'source_without_C' by removing 'C' from 'source'\n",
    "ap_data['ssid'] = ap_data['ssid'].str.replace('C', '')\n",
    "\n",
    "# Convert the 'source_without_C' column to numeric\n",
    "ap_data['ssid'] = pd.to_numeric(ap_data['ssid'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Mac Address : ['6A:BD:12:5B:D6:64' 'F6:CE:87:F2:06:21' 'A2:89:5E:B6:E7:58'\n",
      " '02:9D:2F:8D:49:90' 'FE:47:AD:D7:13:E2' '56:3A:A2:F8:0C:63'\n",
      " '7A:6B:C2:5A:7B:88' '52:39:94:90:76:D2' '1E:03:B6:E0:9E:3C'\n",
      " '56:DE:9D:83:4D:C6' 'B6:6A:AD:C1:CF:19' 'E6:4C:39:FC:36:8B'\n",
      " 'BE:7E:CC:35:1C:46' '7A:44:1F:B5:90:E3' '22:95:8E:C1:1D:93']\n",
      "Unique SSID : [11  5  7  6  1  3  8 10  2  9  4]\n",
      "Unique Channel : [2462 2457 2452 2422 2412 2417 2437 2432 2447 2442 2427]\n",
      "Unique Floor ID : [121 101 102 103 104 105 106 107 108 109 110 111 112 117 118 119 120 127\n",
      " 128 129 130 137 138 139 140 147 148 149 150 157 158 159 160 167 168 169\n",
      " 170 122 123 124 125 126 131 132 133 134 135 136 141 142 143 144 145 146\n",
      " 151 152 153 154 155 156 161 162 163 164 165 166 171 172 173 174 175 176\n",
      " 177 178 179 180 181 182 183 184 185 186 187 188 189   1   2   3   4   5\n",
      "   6   7   8   9  10  11  12  13  14  15  16  17  18]\n"
     ]
    }
   ],
   "source": [
    "#Assess unique values per columns\n",
    "unique_mac_address = ap_data[\"mac_address\"].unique()\n",
    "unique_ssid = ap_data[\"ssid\"].unique()\n",
    "unique_channel = ap_data[\"channel\"].unique()\n",
    "unique_floorid = ap_data[\"floorid\"].unique()\n",
    "\n",
    "print('Unique Mac Address : {}'.format(unique_mac_address))\n",
    "print('Unique SSID : {}'.format(unique_ssid))\n",
    "print('Unique Channel : {}'.format(unique_channel))\n",
    "print('Unique Floor ID : {}'.format(unique_floorid))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocess the Training Data Set //////////////////////////////////////////////////////////////////////////////////////////////"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             mac_address  ssid  channel source  signal_strength  floorid  \\\n",
      "0      6A:BD:12:5B:D6:64    11     2462   cap1              -61      121   \n",
      "1      6A:BD:12:5B:D6:64    11     2462   cap1              -52      121   \n",
      "2      6A:BD:12:5B:D6:64    11     2462   cap1              -53      121   \n",
      "3      6A:BD:12:5B:D6:64    11     2457   cap1              -51      121   \n",
      "4      6A:BD:12:5B:D6:64    11     2462   cap1              -52      121   \n",
      "...                  ...   ...      ...    ...              ...      ...   \n",
      "11811  22:95:8E:C1:1D:93     2     2457   cap2              -65       18   \n",
      "11812  22:95:8E:C1:1D:93     2     2462   cap1              -82       18   \n",
      "11813  FE:47:AD:D7:13:E2     1     2447   cap2              -66       18   \n",
      "11814  22:95:8E:C1:1D:93     2     2462   cap2              -65       18   \n",
      "11815  7A:44:1F:B5:90:E3    11     2412   cap2              -81       18   \n",
      "\n",
      "       latitude   longitude         timestamp  \n",
      "0      7.065750  125.596484  11/11/2023 11:40  \n",
      "1      7.065750  125.596484  11/11/2023 11:40  \n",
      "2      7.065750  125.596484  11/11/2023 11:40  \n",
      "3      7.065750  125.596484  11/11/2023 11:40  \n",
      "4      7.065750  125.596484  11/11/2023 11:40  \n",
      "...         ...         ...               ...  \n",
      "11811  7.065657  125.596435  13/11/2023 13:14  \n",
      "11812  7.065657  125.596435  13/11/2023 13:14  \n",
      "11813  7.065657  125.596435  13/11/2023 13:14  \n",
      "11814  7.065657  125.596435  13/11/2023 13:14  \n",
      "11815  7.065657  125.596435  13/11/2023 13:14  \n",
      "\n",
      "[11816 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "trainingData = ap_data\n",
    "\n",
    "print(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from itertools import product\n",
    "\n",
    "# Assuming 'ap_data' is a DataFrame containing your data\n",
    "\n",
    "# Find unique SSIDs and floor IDs in the dataset\n",
    "unique_ssids = trainingData['ssid'].unique()\n",
    "unique_floor_ids = trainingData['floorid'].unique()\n",
    "\n",
    "# Initialize an empty DataFrame to store the combinations\n",
    "combinations_df = pd.DataFrame(columns=[\n",
    "    'mac_address', 'ssid', 'latitude', 'longitude', 'floorid', 'timestamp',\n",
    "    'channel_cap1', 'channel_cap2', 'channel_cap3',\n",
    "    'signal_strength_cap1', 'signal_strength_cap2', 'signal_strength_cap3'\n",
    "])\n",
    "\n",
    "# Iterate over unique SSIDs, floor IDs, and extract unique channels for each 'cap' category\n",
    "for ssid, floor_id in product(unique_ssids, unique_floor_ids):\n",
    "    # Filter data for the specific SSID and floor ID\n",
    "    specific_ssid_floor_data = trainingData[(trainingData['ssid'] == ssid) & (trainingData['floorid'] == floor_id)]\n",
    "\n",
    "    # Filter data for each 'cap' category within the specific SSID and floor ID\n",
    "    cap1_data = specific_ssid_floor_data[specific_ssid_floor_data['source'] == 'cap1']\n",
    "    cap2_data = specific_ssid_floor_data[specific_ssid_floor_data['source'] == 'cap2']\n",
    "    cap3_data = specific_ssid_floor_data[specific_ssid_floor_data['source'] == 'cap3']\n",
    "\n",
    "    # Extract unique channels for each 'cap' category within the specific SSID and floor ID\n",
    "    unique_channels_cap1 = cap1_data['channel'].unique()\n",
    "    unique_channels_cap2 = cap2_data['channel'].unique()\n",
    "    unique_channels_cap3 = cap3_data['channel'].unique()\n",
    "\n",
    "    # Generate all combinations of unique channels and floor ID\n",
    "    all_combinations = product(unique_channels_cap1, unique_channels_cap2, unique_channels_cap3)\n",
    "\n",
    "    # Append combinations to the DataFrame\n",
    "    for combination in all_combinations:\n",
    "        combinations_df = combinations_df.append({\n",
    "            'mac_address': specific_ssid_floor_data['mac_address'].iloc[0],\n",
    "            'ssid': ssid,\n",
    "            'latitude': specific_ssid_floor_data['latitude'].iloc[0],\n",
    "            'longitude': specific_ssid_floor_data['longitude'].iloc[0],\n",
    "            'floorid': floor_id,\n",
    "            'timestamp': specific_ssid_floor_data['timestamp'].iloc[0],\n",
    "            'channel_cap1': combination[0],\n",
    "            'channel_cap2': combination[1],\n",
    "            'channel_cap3': combination[2],\n",
    "            'signal_strength_cap1': cap1_data[cap1_data['channel'] == combination[0]]['signal_strength'].iloc[0],\n",
    "            'signal_strength_cap2': cap2_data[cap2_data['channel'] == combination[1]]['signal_strength'].iloc[0],\n",
    "            'signal_strength_cap3': cap3_data[cap3_data['channel'] == combination[2]]['signal_strength'].iloc[0],\n",
    "        }, ignore_index=True)\n",
    "\n",
    "# Print the resulting DataFrame with all combinations\n",
    "print(combinations_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(df):\n",
    "    \"\"\"\n",
    "    Perform feature trimming, and engineering for trainingData\n",
    "    Will also be applied to validationData\n",
    "    \n",
    "    INPUT: trainingData DataFrame\n",
    "    OUTPUT: Trimmed and cleaned trainingData DataFrame\n",
    "    \"\"\"\n",
    "    \n",
    "    # Reverse the representation for the values. 100=0 and teh values range from 0-105 (weakest to strongest)\n",
    "    #\"The intensity values are represented as negative integer values ranging -104dBm (extremely poor signal) to 0dbM.\n",
    "    #The positive value 100 is used to denote when a WAP was not detected.\"\n",
    "    df.iloc[:, 9:12] = np.where(df.iloc[:, 9:12] <= 0, \n",
    "                df.iloc[:, 9:12] + 105, \n",
    "                df.iloc[:, 9:12] - 100)\n",
    "    \n",
    "    '''\n",
    "    df.iloc[:, 6:9] = np.where(df.iloc[:, 6:9] > 2000, \n",
    "                df.iloc[:, 6:9] - 2300, \n",
    "                df.iloc[:, 6:9] - 0)\n",
    "    '''\n",
    "    \n",
    "    # remove selected columns... \n",
    "    columns_removed = ['mac_address','timestamp']\n",
    "    for col in columns_removed:\n",
    "        df.drop(col, axis=1, inplace=True)\n",
    "    \n",
    "   \n",
    "    # Return the cleaned dataframe.\n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply Cleaning\n",
    "\n",
    "trainingData  = clean_data(combinations_df)\n",
    "\n",
    "trainingData.to_csv('trainingData.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def preprocess_data(df):\n",
    "    \"\"\"\n",
    "    Separates trainingData into Features and Targets\n",
    "    Will also be applied to validationData\n",
    "    \n",
    "    INPUT: Cleaned trainingData DataFrame\n",
    "    OUTPUT: trainingData as Features and Targets\n",
    "    \"\"\"\n",
    "    # split the data set into features and targets(Floor and BuildingID)\n",
    "    X = df.drop(['longitude', 'latitude', 'floorid'], axis=1)\n",
    "    y = df[['floorid']]\n",
    "    \n",
    "    # Extract unique channel values\n",
    "    unique_channels = sorted(set(df['channel_cap1'].unique()) | set(df['channel_cap2'].unique()) | set(df['channel_cap3'].unique()))\n",
    "    \n",
    "    # Create new one-hot encoded columns\n",
    "    for channel in unique_channels:\n",
    "        X[f'channel_cap1_{channel}'] = (df['channel_cap1'] == channel).astype(int)\n",
    "        X[f'channel_cap2_{channel}'] = (df['channel_cap2'] == channel).astype(int)\n",
    "        X[f'channel_cap3_{channel}'] = (df['channel_cap3'] == channel).astype(int)\n",
    "    \n",
    "    # Drop the original 'channel_cap1', 'channel_cap2', and 'channel_cap3' columns\n",
    "    X.drop(['channel_cap1', 'channel_cap2', 'channel_cap3'], axis=1, inplace=True)\n",
    "    \n",
    "    # Iterate over signal strength caps and channels to perform multiplication\n",
    "    signal_columns = ['signal_strength_cap1', 'signal_strength_cap2', 'signal_strength_cap3']\n",
    "    \n",
    "    for signal_col in signal_columns:\n",
    "        for channel in unique_channels:\n",
    "            channel_col1 = f'channel_cap1_{channel}'\n",
    "            channel_col2 = f'channel_cap2_{channel}'\n",
    "            channel_col3 = f'channel_cap3_{channel}'\n",
    "            \n",
    "            if signal_col.endswith('cap1'):\n",
    "                X[f'{signal_col}_{channel_col1}'] = df[signal_col] * X[channel_col1]\n",
    "            elif signal_col.endswith('cap2'):\n",
    "                X[f'{signal_col}_{channel_col2}'] = df[signal_col] * X[channel_col2]\n",
    "            elif signal_col.endswith('cap3'):\n",
    "                X[f'{signal_col}_{channel_col3}'] = df[signal_col] * X[channel_col3]\n",
    "\n",
    "    # Drop the original 'signal_strength' columns\n",
    "    X.drop(['signal_strength_cap1', 'signal_strength_cap2', 'signal_strength_cap3'], axis=1, inplace=True)\n",
    "    \n",
    "    # Drop unwanted columns\n",
    "    unwanted_columns = [f'channel_cap{i}_{cap}' for i in range(1, 4) for cap in unique_channels]\n",
    "    X.drop(unwanted_columns, axis=1, inplace=True)\n",
    "    \n",
    "    # create Dummies for the targets to feed into the model\n",
    "    y = pd.get_dummies(data=y, columns=['floorid'])\n",
    "    \n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Series' objects are mutable, thus they cannot be hashed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\categorical.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, values, categories, ordered, dtype, fastpath)\u001b[0m\n\u001b[0;32m    342\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 343\u001b[1;33m                 \u001b[0mcodes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcategories\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfactorize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msort\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    344\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\algorithms.py\u001b[0m in \u001b[0;36mfactorize\u001b[1;34m(values, sort, na_sentinel, size_hint)\u001b[0m\n\u001b[0;32m    676\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 677\u001b[1;33m         codes, uniques = _factorize_array(\n\u001b[0m\u001b[0;32m    678\u001b[0m             \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mna_sentinel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mna_sentinel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize_hint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msize_hint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mna_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mna_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\algorithms.py\u001b[0m in \u001b[0;36m_factorize_array\u001b[1;34m(values, na_sentinel, size_hint, na_value, mask)\u001b[0m\n\u001b[0;32m    499\u001b[0m     \u001b[0mtable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhash_klass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize_hint\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 500\u001b[1;33m     uniques, codes = table.factorize(\n\u001b[0m\u001b[0;32m    501\u001b[0m         \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mna_sentinel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mna_sentinel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mna_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mna_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.factorize\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable._unique\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__hash__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1667\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__hash__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1668\u001b[1;33m         raise TypeError(\n\u001b[0m\u001b[0;32m   1669\u001b[0m             \u001b[1;34mf\"{repr(type(self).__name__)} objects are mutable, \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'Series' objects are mutable, thus they cannot be hashed",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-76-7fbe43deb223>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Apply preprocessing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocess_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainingData\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-75-901913a9d96a>\u001b[0m in \u001b[0;36mpreprocess_data\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[1;31m# create Dummies for the targets to feed into the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m     \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_dummies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'floorid'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\reshape.py\u001b[0m in \u001b[0;36mget_dummies\u001b[1;34m(data, prefix, prefix_sep, dummy_na, columns, sparse, drop_first, dtype)\u001b[0m\n\u001b[0;32m    887\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpre\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_to_encode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprefix_sep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m             \u001b[1;31m# col is (column_name, column), use just column data here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             dummy = _get_dummies_1d(\n\u001b[0m\u001b[0;32m    890\u001b[0m                 \u001b[0mcol\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m                 \u001b[0mprefix\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpre\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\reshape.py\u001b[0m in \u001b[0;36m_get_dummies_1d\u001b[1;34m(data, prefix, prefix_sep, dummy_na, sparse, drop_first, dtype)\u001b[0m\n\u001b[0;32m    923\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    924\u001b[0m     \u001b[1;31m# Series avoids inconsistent NaN handling\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 925\u001b[1;33m     \u001b[0mcodes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfactorize_from_iterable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    926\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    927\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\categorical.py\u001b[0m in \u001b[0;36mfactorize_from_iterable\u001b[1;34m(values)\u001b[0m\n\u001b[0;32m   2695\u001b[0m         \u001b[1;31m# but only the resulting categories, the order of which is independent\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2696\u001b[0m         \u001b[1;31m# from ordered. Set ordered to False as default. See GH #15457\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2697\u001b[1;33m         \u001b[0mcat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCategorical\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mordered\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2698\u001b[0m         \u001b[0mcategories\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcategories\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2699\u001b[0m         \u001b[0mcodes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcodes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\categorical.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, values, categories, ordered, dtype, fastpath)\u001b[0m\n\u001b[0;32m    343\u001b[0m                 \u001b[0mcodes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcategories\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfactorize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msort\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 345\u001b[1;33m                 \u001b[0mcodes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcategories\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfactorize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msort\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    346\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mordered\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m                     \u001b[1;31m# raise, as we don't have a sortable data structure and so\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\algorithms.py\u001b[0m in \u001b[0;36mfactorize\u001b[1;34m(values, sort, na_sentinel, size_hint)\u001b[0m\n\u001b[0;32m    675\u001b[0m             \u001b[0mna_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    676\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 677\u001b[1;33m         codes, uniques = _factorize_array(\n\u001b[0m\u001b[0;32m    678\u001b[0m             \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mna_sentinel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mna_sentinel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize_hint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msize_hint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mna_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mna_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    679\u001b[0m         )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\algorithms.py\u001b[0m in \u001b[0;36m_factorize_array\u001b[1;34m(values, na_sentinel, size_hint, na_value, mask)\u001b[0m\n\u001b[0;32m    498\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    499\u001b[0m     \u001b[0mtable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhash_klass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize_hint\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 500\u001b[1;33m     uniques, codes = table.factorize(\n\u001b[0m\u001b[0;32m    501\u001b[0m         \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mna_sentinel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mna_sentinel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mna_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mna_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    502\u001b[0m     )\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.factorize\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable._unique\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__hash__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1666\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1667\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__hash__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1668\u001b[1;33m         raise TypeError(\n\u001b[0m\u001b[0;32m   1669\u001b[0m             \u001b[1;34mf\"{repr(type(self).__name__)} objects are mutable, \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1670\u001b[0m             \u001b[1;34mf\"thus they cannot be hashed\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'Series' objects are mutable, thus they cannot be hashed"
     ]
    }
   ],
   "source": [
    "#Apply preprocessing\n",
    "\n",
    "X, y = preprocess_data(trainingData)\n",
    "\n",
    "\n",
    "#y.to_csv('y_values.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ssid  signal_strength_cap1_channel_cap1_2412  \\\n",
      "0      11                                       0   \n",
      "1      11                                       0   \n",
      "2      11                                       0   \n",
      "3      11                                       0   \n",
      "4      11                                       0   \n",
      "...   ...                                     ...   \n",
      "2486    4                                       0   \n",
      "2487    4                                       0   \n",
      "2488    4                                       0   \n",
      "2489    4                                       0   \n",
      "2490    4                                       0   \n",
      "\n",
      "      signal_strength_cap1_channel_cap1_2417  \\\n",
      "0                                          0   \n",
      "1                                          0   \n",
      "2                                          0   \n",
      "3                                          0   \n",
      "4                                          0   \n",
      "...                                      ...   \n",
      "2486                                       0   \n",
      "2487                                       0   \n",
      "2488                                       0   \n",
      "2489                                       0   \n",
      "2490                                       0   \n",
      "\n",
      "      signal_strength_cap1_channel_cap1_2422  \\\n",
      "0                                          0   \n",
      "1                                          0   \n",
      "2                                          0   \n",
      "3                                          0   \n",
      "4                                          0   \n",
      "...                                      ...   \n",
      "2486                                       0   \n",
      "2487                                       0   \n",
      "2488                                       0   \n",
      "2489                                       0   \n",
      "2490                                       0   \n",
      "\n",
      "      signal_strength_cap1_channel_cap1_2427  \\\n",
      "0                                          0   \n",
      "1                                          0   \n",
      "2                                          0   \n",
      "3                                          0   \n",
      "4                                          0   \n",
      "...                                      ...   \n",
      "2486                                       0   \n",
      "2487                                       0   \n",
      "2488                                       0   \n",
      "2489                                       0   \n",
      "2490                                       0   \n",
      "\n",
      "      signal_strength_cap1_channel_cap1_2432  \\\n",
      "0                                          0   \n",
      "1                                          0   \n",
      "2                                          0   \n",
      "3                                          0   \n",
      "4                                          0   \n",
      "...                                      ...   \n",
      "2486                                       0   \n",
      "2487                                       0   \n",
      "2488                                       0   \n",
      "2489                                       0   \n",
      "2490                                       0   \n",
      "\n",
      "      signal_strength_cap1_channel_cap1_2437  \\\n",
      "0                                          0   \n",
      "1                                          0   \n",
      "2                                          0   \n",
      "3                                          0   \n",
      "4                                          0   \n",
      "...                                      ...   \n",
      "2486                                       0   \n",
      "2487                                       0   \n",
      "2488                                       0   \n",
      "2489                                       0   \n",
      "2490                                       0   \n",
      "\n",
      "      signal_strength_cap1_channel_cap1_2442  \\\n",
      "0                                          0   \n",
      "1                                          0   \n",
      "2                                          0   \n",
      "3                                          0   \n",
      "4                                          0   \n",
      "...                                      ...   \n",
      "2486                                       0   \n",
      "2487                                       0   \n",
      "2488                                       0   \n",
      "2489                                       0   \n",
      "2490                                       0   \n",
      "\n",
      "      signal_strength_cap1_channel_cap1_2447  \\\n",
      "0                                          0   \n",
      "1                                          0   \n",
      "2                                          0   \n",
      "3                                          0   \n",
      "4                                          0   \n",
      "...                                      ...   \n",
      "2486                                       0   \n",
      "2487                                       0   \n",
      "2488                                       0   \n",
      "2489                                       0   \n",
      "2490                                       0   \n",
      "\n",
      "      signal_strength_cap1_channel_cap1_2452  ...  \\\n",
      "0                                          0  ...   \n",
      "1                                          0  ...   \n",
      "2                                          0  ...   \n",
      "3                                          0  ...   \n",
      "4                                          0  ...   \n",
      "...                                      ...  ...   \n",
      "2486                                      26  ...   \n",
      "2487                                      26  ...   \n",
      "2488                                      26  ...   \n",
      "2489                                      26  ...   \n",
      "2490                                      26  ...   \n",
      "\n",
      "      signal_strength_cap3_channel_cap3_2417  \\\n",
      "0                                          0   \n",
      "1                                          0   \n",
      "2                                          0   \n",
      "3                                          0   \n",
      "4                                          0   \n",
      "...                                      ...   \n",
      "2486                                       0   \n",
      "2487                                       0   \n",
      "2488                                       0   \n",
      "2489                                       0   \n",
      "2490                                       0   \n",
      "\n",
      "      signal_strength_cap3_channel_cap3_2422  \\\n",
      "0                                          0   \n",
      "1                                          0   \n",
      "2                                          0   \n",
      "3                                          0   \n",
      "4                                          0   \n",
      "...                                      ...   \n",
      "2486                                       0   \n",
      "2487                                       0   \n",
      "2488                                       0   \n",
      "2489                                       0   \n",
      "2490                                       0   \n",
      "\n",
      "      signal_strength_cap3_channel_cap3_2427  \\\n",
      "0                                          0   \n",
      "1                                          0   \n",
      "2                                          0   \n",
      "3                                          0   \n",
      "4                                          0   \n",
      "...                                      ...   \n",
      "2486                                      17   \n",
      "2487                                       0   \n",
      "2488                                       0   \n",
      "2489                                       0   \n",
      "2490                                      17   \n",
      "\n",
      "      signal_strength_cap3_channel_cap3_2432  \\\n",
      "0                                          0   \n",
      "1                                          0   \n",
      "2                                          0   \n",
      "3                                          0   \n",
      "4                                          0   \n",
      "...                                      ...   \n",
      "2486                                       0   \n",
      "2487                                       0   \n",
      "2488                                      19   \n",
      "2489                                       0   \n",
      "2490                                       0   \n",
      "\n",
      "      signal_strength_cap3_channel_cap3_2437  \\\n",
      "0                                          0   \n",
      "1                                          0   \n",
      "2                                          0   \n",
      "3                                          0   \n",
      "4                                          0   \n",
      "...                                      ...   \n",
      "2486                                       0   \n",
      "2487                                      14   \n",
      "2488                                       0   \n",
      "2489                                       0   \n",
      "2490                                       0   \n",
      "\n",
      "      signal_strength_cap3_channel_cap3_2442  \\\n",
      "0                                          0   \n",
      "1                                          0   \n",
      "2                                          0   \n",
      "3                                          0   \n",
      "4                                         30   \n",
      "...                                      ...   \n",
      "2486                                       0   \n",
      "2487                                       0   \n",
      "2488                                       0   \n",
      "2489                                      21   \n",
      "2490                                       0   \n",
      "\n",
      "      signal_strength_cap3_channel_cap3_2447  \\\n",
      "0                                          0   \n",
      "1                                          0   \n",
      "2                                          0   \n",
      "3                                         23   \n",
      "4                                          0   \n",
      "...                                      ...   \n",
      "2486                                       0   \n",
      "2487                                       0   \n",
      "2488                                       0   \n",
      "2489                                       0   \n",
      "2490                                       0   \n",
      "\n",
      "      signal_strength_cap3_channel_cap3_2452  \\\n",
      "0                                         16   \n",
      "1                                          0   \n",
      "2                                          0   \n",
      "3                                          0   \n",
      "4                                          0   \n",
      "...                                      ...   \n",
      "2486                                       0   \n",
      "2487                                       0   \n",
      "2488                                       0   \n",
      "2489                                       0   \n",
      "2490                                       0   \n",
      "\n",
      "      signal_strength_cap3_channel_cap3_2457  \\\n",
      "0                                          0   \n",
      "1                                          9   \n",
      "2                                          0   \n",
      "3                                          0   \n",
      "4                                          0   \n",
      "...                                      ...   \n",
      "2486                                       0   \n",
      "2487                                       0   \n",
      "2488                                       0   \n",
      "2489                                       0   \n",
      "2490                                       0   \n",
      "\n",
      "      signal_strength_cap3_channel_cap3_2462  \n",
      "0                                          0  \n",
      "1                                          0  \n",
      "2                                         14  \n",
      "3                                          0  \n",
      "4                                          0  \n",
      "...                                      ...  \n",
      "2486                                       0  \n",
      "2487                                       0  \n",
      "2488                                       0  \n",
      "2489                                       0  \n",
      "2490                                       0  \n",
      "\n",
      "[2491 rows x 34 columns]\n"
     ]
    }
   ],
   "source": [
    "print(X)\n",
    "\n",
    "\n",
    "# Replace 'output_file.csv' with the desired file name\n",
    "output_file = 'preprocessed_data.csv'\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "X.to_csv(output_file, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      floorid_101  floorid_104  floorid_121\n",
      "0               0            0            1\n",
      "1               0            0            1\n",
      "2               0            0            1\n",
      "3               0            0            1\n",
      "4               0            0            1\n",
      "...           ...          ...          ...\n",
      "2486            0            1            0\n",
      "2487            0            1            0\n",
      "2488            0            1            0\n",
      "2489            0            1            0\n",
      "2490            0            1            0\n",
      "\n",
      "[2491 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(preprocess_data):\n",
    "# TO AVOID OVERFITTING: Split the training data into training and testing sets \n",
    "    global X_train\n",
    "    global X_test\n",
    "    global y_train\n",
    "    global y_test\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                        y, \n",
    "                                                        test_size = 0.2, \n",
    "                                                        random_state = 42,\n",
    "                                                        shuffle=True)\n",
    "\n",
    "    # Show the results of the split\n",
    "    print(\"Training set has {} samples.\".format(X_train.shape[0]))\n",
    "    print(\"Testing set has {} samples.\".format(X_test.shape[0]))\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set has 12 samples.\n",
      "Testing set has 4 samples.\n"
     ]
    }
   ],
   "source": [
    "#Apply split data\n",
    "\n",
    "X_train, X_test, y_train, y_test = split_data(preprocess_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-48-b12521d0f24b>:15: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  knn.fit(X_train, y_train)\n"
     ]
    }
   ],
   "source": [
    "#Scale Data with Standard Scaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "#Fit only the training set\n",
    "#this will help us transform the validation data \n",
    "scaler.fit(X_train)\n",
    "    \n",
    "# Apply transform to both the training set and the test set.\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "k = 1  # You can adjust the value of k\n",
    "knn = KNeighborsClassifier(n_neighbors=k, p=2, metric = 'euclidean')  # p=2 for Euclidean metric\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Assuming 'knn' is your trained KNN classifier\n",
    "# Assuming 'X_test' and 'y_test' are your test features and labels\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source index    cap1                    cap2                    cap3  \\\n",
      "             channel signal_strength channel signal_strength channel   \n",
      "0          0       0               0    2417             -66    2412   \n",
      "1          1    2412             -57    2417             -63    2412   \n",
      "2          2    2427             -67    2417             -66    2412   \n",
      "\n",
      "source                                                                        \\\n",
      "       signal_strength floorid  latitude   longitude        mac_address ssid   \n",
      "0                  -89     101  7.065735  125.596478  FE:47:AD:D7:13:E2    1   \n",
      "1                  -89     101  7.065735  125.596478  FE:47:AD:D7:13:E2    1   \n",
      "2                  -93     101  7.065735  125.596478  FE:47:AD:D7:13:E2    1   \n",
      "\n",
      "source                      2417    2422    2412    2427  \n",
      "               timestamp channel channel channel channel  \n",
      "0       24/11/2023 12:02       0       0       0       0  \n",
      "1       24/11/2023 12:03       0       0       0       0  \n",
      "2       24/11/2023 12:04       0       0       0       0  \n"
     ]
    }
   ],
   "source": [
    "# Assuming unique_channels is a list containing all unique channel values\n",
    "unique_channels = [2417, 2422, 2412, 2427]\n",
    "\n",
    "# Pivot the DataFrame to create separate columns for each 'cap'\n",
    "ap_data_pivot = ap_data_selected.pivot_table(\n",
    "    index=['mac_address', 'ssid', 'timestamp', 'floorid', 'latitude', 'longitude'],\n",
    "    columns='source',\n",
    "    values=['channel', 'signal_strength'],\n",
    "    aggfunc='first',\n",
    "    fill_value=0  # Specify the fill value for missing entries\n",
    ").reset_index()\n",
    "\n",
    "# Ensure that all unique channel columns are present in the DataFrame\n",
    "for channel in unique_channels:\n",
    "    if ('channel', channel) not in ap_data_pivot.columns:\n",
    "        ap_data_pivot[('channel', channel)] = 0  # Add a column with the missing channel and fill with 0\n",
    "\n",
    "# Sort the columns to have a consistent order\n",
    "ap_data_pivot = ap_data_pivot.reorder_levels([1, 0], axis=1).sort_index(axis=1, level=[0, 1]).reset_index()\n",
    "\n",
    "print(ap_data_pivot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         mac_address  ssid         timestamp  floorid  latitude   longitude  \\\n",
      "0  02:9D:2F:8D:49:90     6  10/11/2023 14:44      101  7.065735  125.596478   \n",
      "1  02:9D:2F:8D:49:90     6  10/11/2023 14:45      101  7.065735  125.596478   \n",
      "2  02:9D:2F:8D:49:90     6  10/11/2023 14:46      101  7.065735  125.596478   \n",
      "3  02:9D:2F:8D:49:90     6  10/11/2023 14:47      101  7.065735  125.596478   \n",
      "4  02:9D:2F:8D:49:90     6  10/11/2023 14:48      101  7.065735  125.596478   \n",
      "\n",
      "   cap1_channel  cap2_channel  cap3_channel  cap1_signal_strength  \\\n",
      "0        2417.0        2417.0        2412.0                 -57.0   \n",
      "1        2417.0        2412.0        2417.0                 -69.0   \n",
      "2        2417.0        2412.0        2412.0                 -65.0   \n",
      "3        2422.0        2422.0        2417.0                 -67.0   \n",
      "4        2422.0        2412.0        2412.0                 -63.0   \n",
      "\n",
      "   cap2_signal_strength  cap3_signal_strength  \n",
      "0                 -74.0                 -94.0  \n",
      "1                 -75.0                 -87.0  \n",
      "2                 -76.0                 -92.0  \n",
      "3                 -77.0                 -93.0  \n",
      "4                 -75.0                 -92.0  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Flatten the MultiIndex columns\n",
    "ap_data_pivot.columns = [f'{col[0]}_{col[1]}' if col[1] else col[0] for col in ap_data_pivot.columns]\n",
    "\n",
    "# Rename columns for clarity\n",
    "ap_data_pivot.columns = [\n",
    "    'mac_address', 'ssid', 'timestamp', 'floorid', 'latitude', 'longitude',\n",
    "    'cap1_channel', 'cap2_channel', 'cap3_channel',\n",
    "    'cap1_signal_strength', 'cap2_signal_strength', 'cap3_signal_strength'\n",
    "]\n",
    "\n",
    "# Replace missing signal_strength values with 100\n",
    "ap_data_pivot['cap1_signal_strength'].fillna(100, inplace=True)\n",
    "ap_data_pivot['cap2_signal_strength'].fillna(100, inplace=True)\n",
    "ap_data_pivot['cap3_signal_strength'].fillna(100, inplace=True)\n",
    "\n",
    "# Replace missing channel values with 0\n",
    "ap_data_pivot['cap1_channel'].fillna(0, inplace=True)\n",
    "ap_data_pivot['cap2_channel'].fillna(0, inplace=True)\n",
    "ap_data_pivot['cap3_channel'].fillna(0, inplace=True)\n",
    "\n",
    "# Remove rows if there are two zeroes in a row in the cap_channel\n",
    "ap_data_pivot = ap_data_pivot[\n",
    "    ~((ap_data_pivot['cap1_channel'] == 0) & (ap_data_pivot['cap2_channel'] == 0)) &\n",
    "    ~((ap_data_pivot['cap1_channel'] == 0) & (ap_data_pivot['cap3_channel'] == 0)) &\n",
    "    ~((ap_data_pivot['cap2_channel'] == 0) & (ap_data_pivot['cap3_channel'] == 0))\n",
    "]\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "ap_data_pivot.to_csv('ap_data_processed-3.csv', index=False)\n",
    "\n",
    "# Print the resulting DataFrame\n",
    "print(ap_data_pivot.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "ap_data_processed_data = r'C:\\Users\\pc\\Desktop\\Thesis\\Untitled Folder 1\\ap_data_processed.csv'\n",
    "ap_data_processed = pd.read_csv(ap_data_processed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1962\n"
     ]
    }
   ],
   "source": [
    "print(len(ap_data_processed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns: 12\n",
      "Number of rows: 1962\n"
     ]
    }
   ],
   "source": [
    "# Check the structure of the data after it's loaded \n",
    "#(print the number of rows and columns).\n",
    "num_rows, num_cols  = ap_data_processed.shape\n",
    "print('Number of columns: {}'.format(num_cols))\n",
    "print('Number of rows: {}'.format(num_rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['mac_address', 'ssid', 'timestamp', 'floorid', 'latitude',\n",
       "       'longitude', 'cap1_channel', 'cap2_channel', 'cap3_channel',\n",
       "       'cap1_signal_strength', 'cap2_signal_strength',\n",
       "       'cap3_signal_strength'], dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check the columns names\n",
    "col_names = ap_data_processed.columns.values\n",
    "col_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Mac Address : ['02:9D:2F:8D:49:90' '1E:03:B6:E0:9E:3C' '22:95:8E:C1:1D:93'\n",
      " '52:39:94:90:76:D2' '56:3A:A2:F8:0C:63' '56:DE:9D:83:4D:C6'\n",
      " '6A:BD:12:5B:D6:64' '7A:44:1F:B5:90:E3' '7A:6B:C2:5A:7B:88'\n",
      " '8E:B0:7A:54:55:A6' 'A2:89:5E:B6:E7:58' 'B6:6A:AD:C1:CF:19'\n",
      " 'BE:7E:CC:35:1C:46' 'E6:4C:39:FC:36:8B' 'F6:CE:87:F2:06:21'\n",
      " 'FE:47:AD:D7:13:E2']\n",
      "Unique SSID : [ 6  2 10  3  9 11  8  7  4  5  1]\n",
      "Unique Floor ID : [101 102 103 104 105 106 107 108 109 110 111 112 117 118 119 120 127 128\n",
      " 129 130 137 138 139 140 147 148 149 150 157 158 159 160 167 168 169 170\n",
      " 187 188 189   1   5   6   7   9  10  11  12  13  14  15  16  17  18 113\n",
      " 114 115 116 121   2   3   4   8 122 123 124 125 126 131 132 133 134 135\n",
      " 136 141 142 143 144 145 146 151 152 153 154 155 156 161 162 163 164 165\n",
      " 166 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186]\n"
     ]
    }
   ],
   "source": [
    "#Assess unique values per building columns\n",
    "unique_mac_address = ap_data_processed[\"mac_address\"].unique()\n",
    "unique_ssid = ap_data_processed[\"ssid\"].unique()\n",
    "#unique_channel_cap1 = ap_data_processed[\"cap1_channel\"].unique()\n",
    "#unique_channel_cap2 = ap_data_processed[\"cap2_channel\"].unique()\n",
    "#unique_channel_cap3 = ap_data_processed[\"cap3_channel\"].unique()\n",
    "unique_floorid = ap_data_processed[\"floorid\"].unique()\n",
    "\n",
    "print('Unique Mac Address : {}'.format(unique_mac_address))\n",
    "print('Unique SSID : {}'.format(unique_ssid))\n",
    "#print('Unique Channel_cap1 : {}'.format(unique_channel_cap1))\n",
    "#print('Unique Channel_cap2 : {}'.format(unique_channel_cap2))\n",
    "#print('Unique Channel_cap3 : {}'.format(unique_channel_cap3))\n",
    "print('Unique Floor ID : {}'.format(unique_floorid))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
